{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Pre-process\n## Download thundersvm (Colab only: cuda9.0 is needed)\nIf you are running the code in colab, you can install thundersvm to fasten the training process. Even if kaggle also provide GPU, CUDA 9.0 cannot be successfully installed because it needs more than another two commands to proceed when downloading in kaggle.(For only one command, it can be proceeded by adding '-[needed command]', but there seems to be no way for more than one.)\n\nIf you are running the code on kaggle, please set the flag 'use_thunder' to False. \nNote: The uploaded cvs file for mnist is produced by thundersvm.","metadata":{"id":"Ude6WG5SND-9"}},{"cell_type":"code","source":"use_thunder = False","metadata":{"execution":{"iopub.status.busy":"2023-01-26T03:12:57.097122Z","iopub.execute_input":"2023-01-26T03:12:57.097583Z","iopub.status.idle":"2023-01-26T03:12:57.102777Z","shell.execute_reply.started":"2023-01-26T03:12:57.097544Z","shell.execute_reply":"2023-01-26T03:12:57.101690Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"if use_thunder:\n    !wget https://developer.nvidia.com/compute/cuda/9.0/Prod/local_installers/cuda-repo-ubuntu1604-9-0-local_9.0.176-1_amd64-deb\n    !dpkg -i cuda-repo-ubuntu1604-9-0-local_9.0.176-1_amd64-deb\n    !apt-key add /var/cuda-repo-9-0-local/7fa2af80.pub\n    !apt-get update\n    !apt-get install cuda=9.0.176-1\n    !pip  install thundersvm","metadata":{"execution":{"iopub.status.busy":"2023-01-25T08:26:52.381832Z","iopub.execute_input":"2023-01-25T08:26:52.383045Z","iopub.status.idle":"2023-01-25T08:26:52.410285Z","shell.execute_reply.started":"2023-01-25T08:26:52.382993Z","shell.execute_reply":"2023-01-25T08:26:52.408358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Import all packages","metadata":{}},{"cell_type":"code","source":"import sys\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn import svm, metrics\nfrom scipy import io\nimport cv2\nfrom skimage import feature as skif\nfrom skimage.feature import hog\n\nif use_thunder:\n    import thundersvm\n\nif sys.version_info[0] < 3:\n    raise Exception(\"Python 3 not detected.\")","metadata":{"execution":{"iopub.status.busy":"2023-01-26T03:12:58.932832Z","iopub.execute_input":"2023-01-26T03:12:58.933245Z","iopub.status.idle":"2023-01-26T03:13:00.182944Z","shell.execute_reply.started":"2023-01-26T03:12:58.933202Z","shell.execute_reply":"2023-01-26T03:13:00.181783Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## Define commonly used functions ","metadata":{"id":"tpzRE6FsbIVA"}},{"cell_type":"code","source":"# Usage: results_to_csv(clf.predict(data_test))\ndef results_to_csv(y_test, data_name):\n    y_test = y_test.astype(int)\n    df = pd.DataFrame({'Category': y_test})\n    df.index += 1 # Ensures that the index starts at 1\n    df.to_csv(data_name + '_submission.csv', index_label='Id')\n    \ndef do_standardize(test_data, train_data):\n    test_data = test_data.reshape(len(test_data), -1)\n    train_data = train_data.reshape(len(train_data), -1)\n    index = len(test_data)\n    print(index)\n    data = np.append(test_data, train_data, axis=0)\n    data = (data - np.min(data))/(np.max(data) - np.min(data))\n    return data[0: index, :], data[index::, :]","metadata":{"executionInfo":{"elapsed":1415,"status":"ok","timestamp":1674526985406,"user":{"displayName":"Cassie lin","userId":"01241741051636242650"},"user_tz":480},"id":"YHKxmpwQT-Zk","execution":{"iopub.status.busy":"2023-01-26T03:12:50.761669Z","iopub.execute_input":"2023-01-26T03:12:50.762490Z","iopub.status.idle":"2023-01-26T03:12:50.771475Z","shell.execute_reply.started":"2023-01-26T03:12:50.762445Z","shell.execute_reply":"2023-01-26T03:12:50.769534Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Load data","metadata":{}},{"cell_type":"code","source":"# Please modify the data path to yours\ndata_dict = {}\nfor data_name in [\"mnist\", \"spam\", \"cifar10\"]:\n    data_dict[data_name] = np.load(f\"/kaggle/input/hw1-dataset/{data_name}-data.npz\")\n    print(\"loaded %s data!\" % data_name)","metadata":{"execution":{"iopub.status.busy":"2023-01-26T03:13:07.869070Z","iopub.execute_input":"2023-01-26T03:13:07.870156Z","iopub.status.idle":"2023-01-26T03:13:08.000500Z","shell.execute_reply.started":"2023-01-26T03:13:07.870110Z","shell.execute_reply":"2023-01-26T03:13:07.999335Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"loaded mnist data!\nloaded spam data!\nloaded cifar10 data!\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Q2. Data partition","metadata":{}},{"cell_type":"code","source":"# partition dataset according to its type, return train set & val set\ndef do_partition(data_name, data, label):\n#     data = data.reshape(len(data), -1)\n    label = label.reshape(len(label), 1)\n    dataset = np.concatenate([data, label], axis=1)\n    np.random.seed()\n    np.random.shuffle(dataset)\n    if data_name == 'mnist':\n        index = 1000\n#         index = 10000\n    elif data_name == 'spam':\n        index = int(len(dataset) * 0.2)\n    else:\n        index = 5000\n    val_set = dataset[0:index]\n    train_set = dataset[index:-1]\n    return train_set, val_set","metadata":{"execution":{"iopub.status.busy":"2023-01-26T03:13:11.062502Z","iopub.execute_input":"2023-01-26T03:13:11.062983Z","iopub.status.idle":"2023-01-26T03:13:11.070466Z","shell.execute_reply.started":"2023-01-26T03:13:11.062939Z","shell.execute_reply":"2023-01-26T03:13:11.069385Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# Q3. Support Vector Machines","metadata":{}},{"cell_type":"code","source":"for data_name in [\"mnist\", \"spam\", \"cifar10\"]:\n    data = data_dict[data_name]\n    fields = \"test_data\", \"training_data\", \"training_labels\"\n    for field in fields:\n        print(field, data[field].shape)\n    test_data, train_data = do_standardize(data['test_data'], data['training_data'])\n    train_set, val_set = do_partition(data_name, train_data, data['training_labels'])\n    train_x = train_set[:, :-1]\n    train_y = train_set[:, -1]\n    val_x = val_set[:, :-1]\n    val_y = val_set[:, -1]\n    if data_name == \"mnist\":\n        train_num_list = [100, 200, 500, 1000, 2000, 5000, 10000]\n    elif data_name == \"spam\":\n        train_num_list = [100, 200, 500, 1000, 2000, len(train_y)]\n    else:\n        train_num_list = [100, 200, 500, 1000, 2000, 5000]\n    model = svm.LinearSVC(dual=False)  # cancel dual to avoid 'ConvergenceWarning'\n    print(\"***********************************************\")\n    print(\"Training model for {}\".format(data_name))\n    train_acc_list = []\n    val_acc_list = []\n    for train_num in train_num_list:\n        print(\"Using {} training examples:\".format(train_num))\n        model.fit(train_x[0:train_num, :], train_y[0:train_num])\n        train_acc = metrics.accuracy_score(train_y, model.predict(train_x))\n        val_acc = metrics.accuracy_score(val_y, model.predict(val_x))\n        print(\"\\tTrain acc: {}\".format(train_acc))\n        print(\"\\tVal acc: {}\".format(val_acc))\n        train_acc_list.append(train_acc)\n        val_acc_list.append(val_acc)\n    plt.figure()\n    plt.title('Train & val acc for {}'.format(data_name))\n    plt.plot(train_num_list, train_acc_list, 'bo', label='Training acc')\n    plt.plot(train_num_list, val_acc_list, 'b', label='Validation acc')\n    plt.legend()\n    plt.savefig(data_name+'.png', bbox_inches='tight')\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-01-25T08:26:52.495544Z","iopub.execute_input":"2023-01-25T08:26:52.496003Z","iopub.status.idle":"2023-01-25T08:26:54.705465Z","shell.execute_reply.started":"2023-01-25T08:26:52.495965Z","shell.execute_reply":"2023-01-25T08:26:54.703514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Q4. Hyperparameter Tuning","metadata":{"id":"LzBQ8SXncPia"}},{"cell_type":"code","source":"data_name = \"mnist\"\ndata = data_dict[data_name]\nprint(\"\\n*********************************************************\")\nprint(\"\\nloaded %s data!\" % data_name)\ntest_data, train_data = do_standardize(data['test_data'], data['training_data'])\ntrain_set, val_set = do_partition(data_name, train_data, data['training_labels'])\ntrain_x = train_set[:, :-1]\ntrain_y = train_set[:, -1]\nval_x = val_set[:, :-1]\nval_y = val_set[:, -1]\n\nprint(\"Training model for {}\".format(data_name))\ntrain_acc_list = []\nval_acc_list = []\ntrain_num = 10000\nc_exp_list = range(-5, 5)\n# c_list = [0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]\nfor c_pow in c_exp_list:\n    c = pow(10, c_pow)\n    model = svm.LinearSVC(dual=False, C=c)  # cancel dual to avoid 'ConvergenceWarning'\n    print(\"Regularization param set to {} :\".format(c))\n    model.fit(train_x[0:train_num, :], train_y[0:train_num])\n    train_acc = metrics.accuracy_score(train_y, model.predict(train_x))\n    val_acc = metrics.accuracy_score(val_y, model.predict(val_x))\n    print(\"\\tTrain acc: {}\".format(train_acc))\n    print(\"\\tVal acc: {}\".format(val_acc))\n    train_acc_list.append(train_acc)\n    val_acc_list.append(val_acc)\nplt.figure()\nplt.title('Train & val acc for {}'.format(data_name))\nplt.plot(c_exp_list, train_acc_list, 'bo', label='Training acc')\nplt.plot(c_exp_list, val_acc_list, 'b', label='Validation acc')\nplt.xlabel('Exp for c (base:10)')\nplt.ylabel('Acc')\nplt.legend()\nplt.savefig(data_name+'_param_tune.png', bbox_inches='tight')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-01-25T08:26:54.707054Z","iopub.status.idle":"2023-01-25T08:26:54.707554Z","shell.execute_reply.started":"2023-01-25T08:26:54.707296Z","shell.execute_reply":"2023-01-25T08:26:54.707317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Q5. K-fold","metadata":{}},{"cell_type":"code","source":"# partition dataset according to its type, return train set & val set\ndef make_dataset(data, label):\n    data = data.reshape(len(data), -1)\n    label = label.reshape(len(label), 1)\n    dataset = np.concatenate([data, label], axis=-1)\n    np.random.seed()\n    np.random.shuffle(dataset)\n    return dataset","metadata":{"execution":{"iopub.status.busy":"2023-01-25T08:26:54.708803Z","iopub.status.idle":"2023-01-25T08:26:54.709242Z","shell.execute_reply.started":"2023-01-25T08:26:54.709033Z","shell.execute_reply":"2023-01-25T08:26:54.709054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_name = \"spam\"\ndata = data_dict[data_name]\nprint(\"\\n*********************************************************\")\nprint(\"\\nloaded %s data!\" % data_name)\ndataset = make_dataset(data['training_data'], data['training_labels'])\n# change k to implement k-fold\nk = 5\nl = int(len(dataset) / k)\nprint(\"Training model for {}\".format(data_name))\n\ntrain_acc_list = []\nval_acc_list = []\ntrain_num = 10000\nc_exp_list = range(-7, 0)\nfor c_pow in c_exp_list:\n    c = pow(10, c_pow)\n    print(\"Regularization param set to {} :\".format(c))\n    tmp_train_acc_list = []\n    tmp_val_acc_list = []\n    for i in range(k):\n        print(\"\\tRound {}\".format(i+1))\n        val_set = dataset[i*l: (i+1)*l, :]\n        train_set = np.append(dataset[0:i * l, :], dataset[ (i+1)*l:-1, :], axis=0)\n        train_x = train_set[:, :-1]\n        train_y = train_set[:, -1]\n        val_x = val_set[:, :-1]\n        val_y = val_set[:, -1]\n\n        model = svm.LinearSVC(dual=False, C=c)  # cancel dual to avoid 'ConvergenceWarning'\n        model.fit(train_x[0:train_num, :], train_y[0:train_num])\n        train_acc = metrics.accuracy_score(train_y, model.predict(train_x))\n        val_acc = metrics.accuracy_score(val_y, model.predict(val_x))\n        print(\"\\t\\tTrain acc: {}\".format(train_acc))\n        print(\"\\t\\tVal acc: {}\".format(val_acc))\n        tmp_train_acc_list.append(train_acc)\n        tmp_val_acc_list.append(val_acc)\n    avg_train_acc = np.average(tmp_train_acc_list)\n    avg_val_acc = np.average(tmp_val_acc_list)\n    train_acc_list.append(avg_train_acc)\n    val_acc_list.append(avg_val_acc)\n    print(\"\\tAverage train acc: {}\".format(avg_train_acc))\n    print(\"\\tAverage val acc: {}\".format(avg_val_acc))\nplt.figure()\nplt.title('Train & val acc for {}'.format(data_name))\nplt.plot(c_exp_list, train_acc_list, 'bo', label='Training acc')\nplt.plot(c_exp_list, val_acc_list, 'b', label='Validation acc')\nplt.xlabel('Exp for c (base:10)')\nplt.ylabel('Acc')\nplt.legend()\nplt.savefig(data_name + '_' + str(k) + 'fold.png', bbox_inches='tight')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-01-25T08:26:54.711647Z","iopub.status.idle":"2023-01-25T08:26:54.712132Z","shell.execute_reply.started":"2023-01-25T08:26:54.71192Z","shell.execute_reply":"2023-01-25T08:26:54.71194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Q6. Kaggle\n## 6.0 Feature extraction","metadata":{}},{"cell_type":"code","source":"def extract_color_features(img):\n    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n    # Split the channels - h,s,v\n    h,s,v = cv2.split(hsv)\n    color_feature = []\n    # The first central moment - average \n    h_mean = np.mean(h) \n    s_mean = np.mean(s) \n    v_mean = np.mean(v) \n    color_feature.extend([h_mean, s_mean, v_mean])\n    # The second central moment - standard deviation\n    h_std = np.std(h)  # np.sqrt(np.mean(abs(h - h.mean())**2))\n    s_std = np.std(s)  # np.sqrt(np.mean(abs(s - s.mean())**2))\n    v_std = np.std(v)  # np.sqrt(np.mean(abs(v - v.mean())**2))\n    color_feature.extend([h_std, s_std, v_std])\n    # The third central moment - the third root of the skewness\n    h_skewness = np.mean(abs(h - h.mean())**3)\n    s_skewness = np.mean(abs(s - s.mean())**3)\n    v_skewness = np.mean(abs(v - v.mean())**3)\n    h_thirdMoment = h_skewness**(1./3)\n    s_thirdMoment = s_skewness**(1./3)\n    v_thirdMoment = v_skewness**(1./3)\n    color_feature.extend([h_thirdMoment, s_thirdMoment, v_thirdMoment])\n#     print(color_feature)\n    return [x/200 for x in color_feature] # div 200 to let model easier to converge\n\ndef extract_lbp_features(img, lbp_radius=1, lbp_point=8):\n    lbp = skif.local_binary_pattern(img, lbp_point, lbp_radius, 'default')\n    max_bins = int(lbp.max() + 1)\n    # hist size:256\n    hist, _ = np.histogram(lbp, density=True, bins=max_bins, range=(0, max_bins))\n    return hist\n\ndef extract_hog_features(img):\n    return hog(img)\n\n\ndef extract_features(data, width=32, height=32, is_rgb=True):\n    image_descriptors = []\n    arr = np.array(data)\n    print(arr.shape)\n    for x in data:\n        if is_rgb:\n            x = x.reshape(3, width, height).T\n            fd = extract_color_features(x)\n            x = cv2.cvtColor(x, cv2.COLOR_BGR2GRAY)\n        else:\n            x = x.reshape(width, height).T\n            fd = []\n        fd = np.append(fd, extract_hog_features(x))\n        fd = np.append(fd, extract_lbp_features(x))\n        image_descriptors.append(fd)\n    return image_descriptors","metadata":{"execution":{"iopub.status.busy":"2023-01-26T03:13:21.415938Z","iopub.execute_input":"2023-01-26T03:13:21.416412Z","iopub.status.idle":"2023-01-26T03:13:21.433255Z","shell.execute_reply.started":"2023-01-26T03:13:21.416370Z","shell.execute_reply":"2023-01-26T03:13:21.432044Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## 6.1 Mnist","metadata":{}},{"cell_type":"code","source":"data_name = \"mnist\"\ndata = data_dict[data_name]\nprint(\"\\nloaded %s data!\" % data_name)\nif use_thunder:\n    test_data, train_data = do_standardize(data[\"test_data\"], data['training_data'])\nelse:\n    test_data = extract_features(data[\"test_data\"], 28, 28, False)\n    train_data = extract_features(data['training_data'], 28, 28, False)\n# train_set, val_set = do_partition(data_name, train_data, data['training_labels'])\n# train_x = train_set[:, :-1]\n# train_y = train_set[:, -1]\n# val_x = val_set[:, :-1]\n# val_y = val_set[:, -1]\ntrain_x = np.array(train_data).reshape(len(train_data), -1)\ntrain_y = data['training_labels']\n\nprint(\"Training model for {}\".format(data_name))\ntrain_acc_list = []\nval_acc_list = []\ntrain_num = len(train_data)\nc_list = [7.5]\nfor c in c_list:\n    if use_thunder:\n        model = thundersvm.SVC(C=c, gamma=0.03)  # best performance, 0.98233\n    else:\n        model = svm.SVC(C=c, kernel=\"poly\", degree=3) # 0.97933\n#         model = svm.LinearSVC(C=c)\n    print(\"Regularization param {}:\".format(c))\n    model.fit(train_x[0:train_num, :], train_y[0:train_num])\n    train_acc = metrics.accuracy_score(train_y, model.predict(train_x))\n#     val_acc = metrics.accuracy_score(val_y, model.predict(val_x))\n    print(\"\\tTrain acc: {}\".format(train_acc))\n#     print(\"\\tVal acc: {}\".format(val_acc))\n    train_acc_list.append(train_acc)\n#     val_acc_list.append(val_acc)\n    results_to_csv(model.predict(test_data), data_name + \"_\" + str(c))","metadata":{"id":"13Wz4cA6S-ie","outputId":"83f7110c-9c43-42ed-fbd0-428b209c4a43","execution":{"iopub.status.busy":"2023-01-26T03:13:32.685557Z","iopub.execute_input":"2023-01-26T03:13:32.686033Z","iopub.status.idle":"2023-01-26T03:17:14.046682Z","shell.execute_reply.started":"2023-01-26T03:13:32.685995Z","shell.execute_reply":"2023-01-26T03:17:14.045299Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"\nloaded mnist data!\n(10000, 1, 28, 28)\n(60000, 1, 28, 28)\nTraining model for mnist\nRegularization param 7.5:\n\tTrain acc: 0.9935666666666667\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Train model for spam","metadata":{"id":"Ei1qjb5wcdZV"}},{"cell_type":"code","source":"data_dict[\"spam\"] = np.load(f\"/kaggle/input/spam-data-v2/spam-data-2.npz\")","metadata":{"execution":{"iopub.status.busy":"2023-01-25T08:34:41.142031Z","iopub.execute_input":"2023-01-25T08:34:41.142497Z","iopub.status.idle":"2023-01-25T08:34:41.148838Z","shell.execute_reply.started":"2023-01-25T08:34:41.142453Z","shell.execute_reply":"2023-01-25T08:34:41.147654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_name = \"spam\"\ndata = data_dict[data_name]\nprint(\"\\n*********************************************************\")\nprint(\"\\nloaded %s data!\" % data_name)\ntest_data = data[\"test_data\"]\ntrain_data = data['training_data']\ntest_data, train_data = do_standardize(test_data, train_data)\ntrain_set, val_set = do_partition(data_name, train_data, data['training_labels'])\ntrain_x = train_set[:, :-1]\ntrain_y = train_set[:, -1]\nval_x = val_set[:, :-1]\nval_y = val_set[:, -1]\n\nprint(\"Training model for {}\".format(data_name))\ntrain_acc_list = []\nval_acc_list = []\ntrain_num = len(train_data)\n# c_list = [90000, 100000, 110000]\n# gamma_list = [900, 1000, 2000]\nc_list = [100000]\ngamma_list = [900]\nfor c in c_list:\n    for gamma in gamma_list:\n        if use_thunder:\n            model = thundersvm.SVC(C=c, gamma=gamma)\n        else:\n            model = svm.SVC(C=c, gamma=gamma)\n        print(\"Regularization param {}, gamma {} :\".format(c, gamma))\n        model.fit(train_x[0:train_num, :], train_y[0:train_num])\n        train_acc = metrics.accuracy_score(train_y, model.predict(train_x))\n        val_acc = metrics.accuracy_score(val_y, model.predict(val_x))\n        print(\"\\tTrain acc: {}\".format(train_acc))\n        print(\"\\tVal acc: {}\".format(val_acc))\n        train_acc_list.append(train_acc)\n        val_acc_list.append(val_acc)\n        results_to_csv(model.predict(test_data), data_name + \"_\" + str(c) + \"_\" + str(gamma))\n","metadata":{"executionInfo":{"elapsed":24804,"status":"ok","timestamp":1674502267453,"user":{"displayName":"Cassie lin","userId":"01241741051636242650"},"user_tz":480},"id":"XdTftREaWdvb","outputId":"73e94aea-8dbc-475c-8af1-c43ca0c8460a","execution":{"iopub.status.busy":"2023-01-25T08:38:12.187044Z","iopub.execute_input":"2023-01-25T08:38:12.187506Z","iopub.status.idle":"2023-01-25T08:38:18.60946Z","shell.execute_reply.started":"2023-01-25T08:38:12.187461Z","shell.execute_reply":"2023-01-25T08:38:18.608193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train model for cifar10\nUse color features, LBP features, HOG features to train a linear classifer.","metadata":{"id":"0n4-ojaAJVZ5"}},{"cell_type":"code","source":"import sys\nif sys.version_info[0] < 3:\n    raise Exception(\"Python 3 not detected.\")\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn import svm, metrics\nfrom scipy import io\n\n    \nif __name__ == \"__main__\":\n    data_name = \"cifar10\"\n    data = np.load(f\"/kaggle/input/hw1-dataset/{data_name}-data.npz\")\n    print(\"\\n*********************************************************\")\n    print(\"\\nloaded %s data!\" % data_name)\n    test_data = extract_features(data[\"test_data\"])\n    train_data = extract_features(data['training_data'])\n    train_set, val_set = do_partition(data_name, train_data, data['training_labels'])\n\n    train_x = train_set[:, :-1]\n    train_y = train_set[:, -1]\n    print(\"Train data:{}, Train label:{}\".format(len(train_x), len(train_y)))\n    val_x = val_set[:, :-1]\n    val_y = val_set[:, -1]\n\n    print(\"Training model for {}\".format(data_name))\n    train_acc_list = []\n    val_acc_list = []\n    train_num = len(data['training_data'])\n    print(train_num)\n#     c_list = [0.1, 1, 10, 100]\n    c_list = [1]\n    for c in c_list:\n            model = svm.LinearSVC(C=c) \n            print(\"Regularization param {} :\".format(c))\n            model.fit(train_x, train_y)\n            train_acc = metrics.accuracy_score(train_y, model.predict(train_x))\n            val_acc = metrics.accuracy_score(val_y, model.predict(val_x))\n            print(\"\\tTrain acc: {}\".format(train_acc))\n            print(\"\\tVal acc: {}\".format(val_acc))\n            train_acc_list.append(train_acc)\n            val_acc_list.append(val_acc)\n            results_to_csv(model.predict(test_data), \"col_hog_lbp_\" + data_name + \"_\" + str(c))","metadata":{"id":"EhhlI6-dJdhi","execution":{"iopub.status.busy":"2023-01-25T08:26:54.719095Z","iopub.status.idle":"2023-01-25T08:26:54.719527Z","shell.execute_reply.started":"2023-01-25T08:26:54.719291Z","shell.execute_reply":"2023-01-25T08:26:54.719309Z"},"trusted":true},"execution_count":null,"outputs":[]}]}